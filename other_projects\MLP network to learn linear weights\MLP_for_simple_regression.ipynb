{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP for simple regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krajkumar6/deeplearning/blob/master/other_projects%5CMLP%20network%20to%20learn%20linear%20weights%5CMLP_for_simple_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gLFhzAsWy0U6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7NsTpYY60dBY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a71QEtky0m_4",
        "colab_type": "code",
        "outputId": "c584c88d-2f84-4fdf-da4b-8f40f45401f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/My Drive/Colab Notebooks/Deep Learning Projects/MLP for learning weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/Deep Learning Projects/MLP for learning weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "23tkH9FS2e3H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Read and Prepare the data"
      ]
    },
    {
      "metadata": {
        "id": "eFSF6EjezLVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yBAtCAmJz8SP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_columns = ['x1','x2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bCDVoOWb2pmJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = df[data_columns]\n",
        "target = df['y']\n",
        "inputs = torch.tensor(inputs.values).float()\n",
        "target = torch.tensor(target.values).float()\n",
        "\n",
        "test_data = torch.tensor(test_data.values).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vuo9lXia81ZS",
        "colab_type": "code",
        "outputId": "6ad1c0c8-75eb-4f03-9eb0-e535438af1d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('Input Size is {}'.format(inputs.size()))\n",
        "print('Target Size is {}'.format(target.size()))\n",
        "\n",
        "print('Test Size is {}'.format(test_data.size()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Size is torch.Size([100, 2])\n",
            "Target Size is torch.Size([100])\n",
            "Test Size is torch.Size([20, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TNOK0DyRNOms",
        "colab_type": "code",
        "outputId": "ecf00cd3-7c4d-4fbd-a7d5-2bf13c208170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print(inputs[:5])\n",
        "print(target[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3.,  5.],\n",
            "        [42., 39.],\n",
            "        [39., 25.],\n",
            "        [21., 24.],\n",
            "        [ 7., 32.]])\n",
            "tensor([ 42., 402., 306., 228., 220.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cWSC9UeO25vS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #number of workers\n",
        "# num_workers = 0\n",
        "\n",
        "# #batch size\n",
        "# batch_size = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HDFllwXb71AS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define the Network Architecture"
      ]
    },
    {
      "metadata": {
        "id": "SF4_RJxq74Zj",
        "colab_type": "code",
        "outputId": "bf39db78-2d6c-4eec-9965-5f3a53c9db3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    \n",
        "    hidden1 = 3\n",
        "    hidden2 = 5 \n",
        "\n",
        "    self.fc1 = nn.Linear(2,hidden1)\n",
        "    self.fc2 = nn.Linear(hidden1,hidden2)\n",
        "    self.fc3 = nn.Linear(hidden2,1)\n",
        "    \n",
        "     \n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "    \n",
        "#instantiate the model\n",
        "\n",
        "model = Net()\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=2, out_features=3, bias=True)\n",
            "  (fc2): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (fc3): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fT8I45CYT6X3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Specify Loss function & Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "kH_CoGAuUAmh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j_I6M7bGRJ1Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ]
    },
    {
      "metadata": {
        "id": "ncwJh6-rQ7e5",
        "colab_type": "code",
        "outputId": "e4eaf722-2a74-4d72-889d-ce7bcbc0c415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        }
      },
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "#epochs\n",
        "epochs = 2000\n",
        "\n",
        "\n",
        "for x in range(epochs):\n",
        "  #initialize the training loss to 0\n",
        "  train_loss = 0\n",
        "  #clear out gradients\n",
        "  optimizer.zero_grad() \n",
        "  \n",
        "  #calculate the output\n",
        "  output = model(inputs)\n",
        "  \n",
        "  #calculate loss\n",
        "  loss = criterion(output,target)\n",
        "  \n",
        "  #backpropagate\n",
        "  loss.backward() \n",
        "  \n",
        "  #update parameters\n",
        "  optimizer.step()\n",
        "  \n",
        "  if ((x%10)==0):\n",
        "    print('Training Loss after epoch {:2d} is {:2.6f}'.format(x,loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss after epoch  0 is 75940.937500\n",
            "Training Loss after epoch 10 is 75452.031250\n",
            "Training Loss after epoch 20 is 75083.031250\n",
            "Training Loss after epoch 30 is 74797.062500\n",
            "Training Loss after epoch 40 is 74565.687500\n",
            "Training Loss after epoch 50 is 74370.039062\n",
            "Training Loss after epoch 60 is 74200.390625\n",
            "Training Loss after epoch 70 is 74044.273438\n",
            "Training Loss after epoch 80 is 73891.898438\n",
            "Training Loss after epoch 90 is 73735.851562\n",
            "Training Loss after epoch 100 is 73568.281250\n",
            "Training Loss after epoch 110 is 73380.132812\n",
            "Training Loss after epoch 120 is 73171.781250\n",
            "Training Loss after epoch 130 is 72923.945312\n",
            "Training Loss after epoch 140 is 72613.601562\n",
            "Training Loss after epoch 150 is 72212.085938\n",
            "Training Loss after epoch 160 is 71676.210938\n",
            "Training Loss after epoch 170 is 70935.335938\n",
            "Training Loss after epoch 180 is 69880.617188\n",
            "Training Loss after epoch 190 is 68326.046875\n",
            "Training Loss after epoch 200 is 65964.929688\n",
            "Training Loss after epoch 210 is 62322.054688\n",
            "Training Loss after epoch 220 is 56691.417969\n",
            "Training Loss after epoch 230 is 48334.042969\n",
            "Training Loss after epoch 240 is 37715.652344\n",
            "Training Loss after epoch 250 is 28017.162109\n",
            "Training Loss after epoch 260 is 22690.601562\n",
            "Training Loss after epoch 270 is 20995.537109\n",
            "Training Loss after epoch 280 is 20601.513672\n",
            "Training Loss after epoch 290 is 20484.933594\n",
            "Training Loss after epoch 300 is 20417.955078\n",
            "Training Loss after epoch 310 is 20363.177734\n",
            "Training Loss after epoch 320 is 20314.708984\n",
            "Training Loss after epoch 330 is 20271.208984\n",
            "Training Loss after epoch 340 is 20232.021484\n",
            "Training Loss after epoch 350 is 20196.644531\n",
            "Training Loss after epoch 360 is 20164.654297\n",
            "Training Loss after epoch 370 is 20135.677734\n",
            "Training Loss after epoch 380 is 20109.386719\n",
            "Training Loss after epoch 390 is 20085.494141\n",
            "Training Loss after epoch 400 is 20063.732422\n",
            "Training Loss after epoch 410 is 20043.832031\n",
            "Training Loss after epoch 420 is 20025.654297\n",
            "Training Loss after epoch 430 is 20009.031250\n",
            "Training Loss after epoch 440 is 19993.798828\n",
            "Training Loss after epoch 450 is 19979.828125\n",
            "Training Loss after epoch 460 is 19966.992188\n",
            "Training Loss after epoch 470 is 19955.181641\n",
            "Training Loss after epoch 480 is 19944.298828\n",
            "Training Loss after epoch 490 is 19934.251953\n",
            "Training Loss after epoch 500 is 19924.968750\n",
            "Training Loss after epoch 510 is 19916.375000\n",
            "Training Loss after epoch 520 is 19908.404297\n",
            "Training Loss after epoch 530 is 19901.007812\n",
            "Training Loss after epoch 540 is 19894.123047\n",
            "Training Loss after epoch 550 is 19887.710938\n",
            "Training Loss after epoch 560 is 19881.726562\n",
            "Training Loss after epoch 570 is 19876.082031\n",
            "Training Loss after epoch 580 is 19870.775391\n",
            "Training Loss after epoch 590 is 19865.798828\n",
            "Training Loss after epoch 600 is 19861.119141\n",
            "Training Loss after epoch 610 is 19856.714844\n",
            "Training Loss after epoch 620 is 19852.554688\n",
            "Training Loss after epoch 630 is 19848.566406\n",
            "Training Loss after epoch 640 is 19844.794922\n",
            "Training Loss after epoch 650 is 19841.162109\n",
            "Training Loss after epoch 660 is 19837.695312\n",
            "Training Loss after epoch 670 is 19834.396484\n",
            "Training Loss after epoch 680 is 19831.255859\n",
            "Training Loss after epoch 690 is 19828.261719\n",
            "Training Loss after epoch 700 is 19825.404297\n",
            "Training Loss after epoch 710 is 19822.697266\n",
            "Training Loss after epoch 720 is 19820.103516\n",
            "Training Loss after epoch 730 is 19817.615234\n",
            "Training Loss after epoch 740 is 19815.222656\n",
            "Training Loss after epoch 750 is 19812.925781\n",
            "Training Loss after epoch 760 is 19810.750000\n",
            "Training Loss after epoch 770 is 19808.656250\n",
            "Training Loss after epoch 780 is 19806.630859\n",
            "Training Loss after epoch 790 is 19804.675781\n",
            "Training Loss after epoch 800 is 19802.794922\n",
            "Training Loss after epoch 810 is 19801.009766\n",
            "Training Loss after epoch 820 is 19799.273438\n",
            "Training Loss after epoch 830 is 19797.585938\n",
            "Training Loss after epoch 840 is 19795.976562\n",
            "Training Loss after epoch 850 is 19794.421875\n",
            "Training Loss after epoch 860 is 19792.902344\n",
            "Training Loss after epoch 870 is 19791.421875\n",
            "Training Loss after epoch 880 is 19789.972656\n",
            "Training Loss after epoch 890 is 19788.554688\n",
            "Training Loss after epoch 900 is 19787.167969\n",
            "Training Loss after epoch 910 is 19785.841797\n",
            "Training Loss after epoch 920 is 19784.542969\n",
            "Training Loss after epoch 930 is 19783.263672\n",
            "Training Loss after epoch 940 is 19782.007812\n",
            "Training Loss after epoch 950 is 19780.773438\n",
            "Training Loss after epoch 960 is 19779.554688\n",
            "Training Loss after epoch 970 is 19778.355469\n",
            "Training Loss after epoch 980 is 19777.175781\n",
            "Training Loss after epoch 990 is 19776.007812\n",
            "Training Loss after epoch 1000 is 19774.857422\n",
            "Training Loss after epoch 1010 is 19773.720703\n",
            "Training Loss after epoch 1020 is 19772.597656\n",
            "Training Loss after epoch 1030 is 19771.488281\n",
            "Training Loss after epoch 1040 is 19770.388672\n",
            "Training Loss after epoch 1050 is 19769.302734\n",
            "Training Loss after epoch 1060 is 19768.208984\n",
            "Training Loss after epoch 1070 is 19767.126953\n",
            "Training Loss after epoch 1080 is 19766.054688\n",
            "Training Loss after epoch 1090 is 19764.994141\n",
            "Training Loss after epoch 1100 is 19763.943359\n",
            "Training Loss after epoch 1110 is 19762.900391\n",
            "Training Loss after epoch 1120 is 19761.871094\n",
            "Training Loss after epoch 1130 is 19760.849609\n",
            "Training Loss after epoch 1140 is 19759.837891\n",
            "Training Loss after epoch 1150 is 19758.832031\n",
            "Training Loss after epoch 1160 is 19757.833984\n",
            "Training Loss after epoch 1170 is 19756.845703\n",
            "Training Loss after epoch 1180 is 19755.865234\n",
            "Training Loss after epoch 1190 is 19754.892578\n",
            "Training Loss after epoch 1200 is 19753.925781\n",
            "Training Loss after epoch 1210 is 19752.966797\n",
            "Training Loss after epoch 1220 is 19752.011719\n",
            "Training Loss after epoch 1230 is 19751.064453\n",
            "Training Loss after epoch 1240 is 19750.125000\n",
            "Training Loss after epoch 1250 is 19749.191406\n",
            "Training Loss after epoch 1260 is 19748.261719\n",
            "Training Loss after epoch 1270 is 19747.339844\n",
            "Training Loss after epoch 1280 is 19746.421875\n",
            "Training Loss after epoch 1290 is 19745.509766\n",
            "Training Loss after epoch 1300 is 19744.601562\n",
            "Training Loss after epoch 1310 is 19743.699219\n",
            "Training Loss after epoch 1320 is 19742.804688\n",
            "Training Loss after epoch 1330 is 19741.912109\n",
            "Training Loss after epoch 1340 is 19741.025391\n",
            "Training Loss after epoch 1350 is 19740.142578\n",
            "Training Loss after epoch 1360 is 19739.263672\n",
            "Training Loss after epoch 1370 is 19738.388672\n",
            "Training Loss after epoch 1380 is 19737.519531\n",
            "Training Loss after epoch 1390 is 19736.654297\n",
            "Training Loss after epoch 1400 is 19735.791016\n",
            "Training Loss after epoch 1410 is 19734.931641\n",
            "Training Loss after epoch 1420 is 19734.076172\n",
            "Training Loss after epoch 1430 is 19733.220703\n",
            "Training Loss after epoch 1440 is 19732.373047\n",
            "Training Loss after epoch 1450 is 19731.531250\n",
            "Training Loss after epoch 1460 is 19730.691406\n",
            "Training Loss after epoch 1470 is 19729.851562\n",
            "Training Loss after epoch 1480 is 19729.019531\n",
            "Training Loss after epoch 1490 is 19728.187500\n",
            "Training Loss after epoch 1500 is 19727.363281\n",
            "Training Loss after epoch 1510 is 19726.537109\n",
            "Training Loss after epoch 1520 is 19725.714844\n",
            "Training Loss after epoch 1530 is 19724.896484\n",
            "Training Loss after epoch 1540 is 19724.080078\n",
            "Training Loss after epoch 1550 is 19723.267578\n",
            "Training Loss after epoch 1560 is 19722.457031\n",
            "Training Loss after epoch 1570 is 19721.650391\n",
            "Training Loss after epoch 1580 is 19720.843750\n",
            "Training Loss after epoch 1590 is 19720.042969\n",
            "Training Loss after epoch 1600 is 19719.242188\n",
            "Training Loss after epoch 1610 is 19718.443359\n",
            "Training Loss after epoch 1620 is 19717.648438\n",
            "Training Loss after epoch 1630 is 19716.853516\n",
            "Training Loss after epoch 1640 is 19716.062500\n",
            "Training Loss after epoch 1650 is 19715.277344\n",
            "Training Loss after epoch 1660 is 19714.494141\n",
            "Training Loss after epoch 1670 is 19713.712891\n",
            "Training Loss after epoch 1680 is 19712.935547\n",
            "Training Loss after epoch 1690 is 19712.158203\n",
            "Training Loss after epoch 1700 is 19711.380859\n",
            "Training Loss after epoch 1710 is 19710.607422\n",
            "Training Loss after epoch 1720 is 19709.835938\n",
            "Training Loss after epoch 1730 is 19709.066406\n",
            "Training Loss after epoch 1740 is 19708.296875\n",
            "Training Loss after epoch 1750 is 19707.529297\n",
            "Training Loss after epoch 1760 is 19706.763672\n",
            "Training Loss after epoch 1770 is 19705.998047\n",
            "Training Loss after epoch 1780 is 19705.234375\n",
            "Training Loss after epoch 1790 is 19704.472656\n",
            "Training Loss after epoch 1800 is 19703.712891\n",
            "Training Loss after epoch 1810 is 19702.953125\n",
            "Training Loss after epoch 1820 is 19702.195312\n",
            "Training Loss after epoch 1830 is 19701.439453\n",
            "Training Loss after epoch 1840 is 19700.683594\n",
            "Training Loss after epoch 1850 is 19699.927734\n",
            "Training Loss after epoch 1860 is 19699.175781\n",
            "Training Loss after epoch 1870 is 19698.423828\n",
            "Training Loss after epoch 1880 is 19697.673828\n",
            "Training Loss after epoch 1890 is 19696.921875\n",
            "Training Loss after epoch 1900 is 19696.173828\n",
            "Training Loss after epoch 1910 is 19695.427734\n",
            "Training Loss after epoch 1920 is 19694.677734\n",
            "Training Loss after epoch 1930 is 19693.933594\n",
            "Training Loss after epoch 1940 is 19693.187500\n",
            "Training Loss after epoch 1950 is 19692.443359\n",
            "Training Loss after epoch 1960 is 19691.701172\n",
            "Training Loss after epoch 1970 is 19690.957031\n",
            "Training Loss after epoch 1980 is 19690.218750\n",
            "Training Loss after epoch 1990 is 19689.476562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2f5KHHS67ulg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inference Section"
      ]
    },
    {
      "metadata": {
        "id": "-xwlKrAj46wk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#set the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "#Test the model on unseen data\n",
        "\n",
        "test_output = model(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a-NVF47j9Sb4",
        "colab_type": "code",
        "outputId": "8b4d470d-3836-4357-aac6-4649b0007222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Test Output Size is {}'.format(test_output.size()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Output Size is torch.Size([20, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b-wlf-3d9jzN",
        "colab_type": "code",
        "outputId": "35bb672f-ee5f-4f28-88b2-bfb1b23591b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3.,  5.],\n",
            "        [48.,  7.],\n",
            "        [46., 21.],\n",
            "        [31., 50.],\n",
            "        [ 2., 16.],\n",
            "        [35., 24.],\n",
            "        [39.,  8.],\n",
            "        [23., 33.],\n",
            "        [19., 35.],\n",
            "        [38., 46.],\n",
            "        [38., 38.],\n",
            "        [39., 22.],\n",
            "        [39.,  2.],\n",
            "        [24., 31.],\n",
            "        [16., 21.],\n",
            "        [14., 37.],\n",
            "        [44.,  2.],\n",
            "        [42., 30.],\n",
            "        [20., 20.],\n",
            "        [40.,  2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hZ0JJ7zN8MSs",
        "colab_type": "code",
        "outputId": "2fbceb3c-000d-4b01-c988-a5cfb65082a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 35.2820],\n",
            "        [229.7600],\n",
            "        [282.9330],\n",
            "        [348.2729],\n",
            "        [ 79.3581],\n",
            "        [250.7019],\n",
            "        [197.0070],\n",
            "        [240.6697],\n",
            "        [232.9380],\n",
            "        [359.6095],\n",
            "        [324.5086],\n",
            "        [258.4336],\n",
            "        [170.6814],\n",
            "        [236.0212],\n",
            "        [159.1313],\n",
            "        [221.0796],\n",
            "        [191.3150],\n",
            "        [305.9147],\n",
            "        [171.2505],\n",
            "        [174.8081]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qUPKGfzu8T6D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}